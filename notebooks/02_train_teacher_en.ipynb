{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6531f0bc4cef499f844571936d1f144e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d95ca7a5ad5b493f803b45d89cac95b1",
              "IPY_MODEL_3428c655ffef4ae2b8875ced14291bb8",
              "IPY_MODEL_47ea253f4cd54860b404f4f5a12f1b8b"
            ],
            "layout": "IPY_MODEL_071fe898b92d46aba9c0842bbd1b28eb"
          }
        },
        "d95ca7a5ad5b493f803b45d89cac95b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_331d5668b4f243bda95a59bc9870ad6b",
            "placeholder": "​",
            "style": "IPY_MODEL_52e5f59d9cb343ed9b870b0764c3b288",
            "value": "Map: 100%"
          }
        },
        "3428c655ffef4ae2b8875ced14291bb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef9a5ef8687f41779e60492e7e9344fb",
            "max": 872,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8f2813785aa94a9fbebb490c625b92cf",
            "value": 872
          }
        },
        "47ea253f4cd54860b404f4f5a12f1b8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfccd50ede6e4b9784792f98187ef1b0",
            "placeholder": "​",
            "style": "IPY_MODEL_dd167b9772e84325a3c113e12b0a60fe",
            "value": " 872/872 [00:00&lt;00:00, 2223.93 examples/s]"
          }
        },
        "071fe898b92d46aba9c0842bbd1b28eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "331d5668b4f243bda95a59bc9870ad6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52e5f59d9cb343ed9b870b0764c3b288": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef9a5ef8687f41779e60492e7e9344fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f2813785aa94a9fbebb490c625b92cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cfccd50ede6e4b9784792f98187ef1b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd167b9772e84325a3c113e12b0a60fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEqpn6BGLiMv",
        "outputId": "4ebbe254-61a3-48a3-9b71-cd5e4d9f34ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.4.1)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (22.0.0)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U transformers datasets evaluate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "import evaluate\n",
        "import numpy as np\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
      ],
      "metadata": {
        "id": "HSrkJ3mQLxlB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y wandb\n"
      ],
      "metadata": {
        "id": "BdUKYkjiWZXN",
        "outputId": "3335d78c-0901-4a79-dede-db987647d285",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: wandb 0.23.0\n",
            "Uninstalling wandb-0.23.0:\n",
            "  Successfully uninstalled wandb-0.23.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sst2 = load_dataset(\"glue\", \"sst2\")"
      ],
      "metadata": {
        "id": "5p7-NQ7rLtm3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"xlm-roberta-base\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=2  # 0 = negative, 1 = positive\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUfyEpNLMChq",
        "outputId": "6711698a-658d-4089-bc31-954771728827"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(name, param.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHETnzs2N1L5",
        "outputId": "fdea7913-55b2-4e59-d084-2d91514fced4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "roberta.embeddings.word_embeddings.weight torch.Size([250002, 768])\n",
            "roberta.embeddings.position_embeddings.weight torch.Size([514, 768])\n",
            "roberta.embeddings.token_type_embeddings.weight torch.Size([1, 768])\n",
            "roberta.embeddings.LayerNorm.weight torch.Size([768])\n",
            "roberta.embeddings.LayerNorm.bias torch.Size([768])\n",
            "roberta.encoder.layer.0.attention.self.query.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.0.attention.self.query.bias torch.Size([768])\n",
            "roberta.encoder.layer.0.attention.self.key.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.0.attention.self.key.bias torch.Size([768])\n",
            "roberta.encoder.layer.0.attention.self.value.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.0.attention.self.value.bias torch.Size([768])\n",
            "roberta.encoder.layer.0.attention.output.dense.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.0.attention.output.dense.bias torch.Size([768])\n",
            "roberta.encoder.layer.0.attention.output.LayerNorm.weight torch.Size([768])\n",
            "roberta.encoder.layer.0.attention.output.LayerNorm.bias torch.Size([768])\n",
            "roberta.encoder.layer.0.intermediate.dense.weight torch.Size([3072, 768])\n",
            "roberta.encoder.layer.0.intermediate.dense.bias torch.Size([3072])\n",
            "roberta.encoder.layer.0.output.dense.weight torch.Size([768, 3072])\n",
            "roberta.encoder.layer.0.output.dense.bias torch.Size([768])\n",
            "roberta.encoder.layer.0.output.LayerNorm.weight torch.Size([768])\n",
            "roberta.encoder.layer.0.output.LayerNorm.bias torch.Size([768])\n",
            "roberta.encoder.layer.1.attention.self.query.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.1.attention.self.query.bias torch.Size([768])\n",
            "roberta.encoder.layer.1.attention.self.key.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.1.attention.self.key.bias torch.Size([768])\n",
            "roberta.encoder.layer.1.attention.self.value.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.1.attention.self.value.bias torch.Size([768])\n",
            "roberta.encoder.layer.1.attention.output.dense.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.1.attention.output.dense.bias torch.Size([768])\n",
            "roberta.encoder.layer.1.attention.output.LayerNorm.weight torch.Size([768])\n",
            "roberta.encoder.layer.1.attention.output.LayerNorm.bias torch.Size([768])\n",
            "roberta.encoder.layer.1.intermediate.dense.weight torch.Size([3072, 768])\n",
            "roberta.encoder.layer.1.intermediate.dense.bias torch.Size([3072])\n",
            "roberta.encoder.layer.1.output.dense.weight torch.Size([768, 3072])\n",
            "roberta.encoder.layer.1.output.dense.bias torch.Size([768])\n",
            "roberta.encoder.layer.1.output.LayerNorm.weight torch.Size([768])\n",
            "roberta.encoder.layer.1.output.LayerNorm.bias torch.Size([768])\n",
            "roberta.encoder.layer.2.attention.self.query.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.2.attention.self.query.bias torch.Size([768])\n",
            "roberta.encoder.layer.2.attention.self.key.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.2.attention.self.key.bias torch.Size([768])\n",
            "roberta.encoder.layer.2.attention.self.value.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.2.attention.self.value.bias torch.Size([768])\n",
            "roberta.encoder.layer.2.attention.output.dense.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.2.attention.output.dense.bias torch.Size([768])\n",
            "roberta.encoder.layer.2.attention.output.LayerNorm.weight torch.Size([768])\n",
            "roberta.encoder.layer.2.attention.output.LayerNorm.bias torch.Size([768])\n",
            "roberta.encoder.layer.2.intermediate.dense.weight torch.Size([3072, 768])\n",
            "roberta.encoder.layer.2.intermediate.dense.bias torch.Size([3072])\n",
            "roberta.encoder.layer.2.output.dense.weight torch.Size([768, 3072])\n",
            "roberta.encoder.layer.2.output.dense.bias torch.Size([768])\n",
            "roberta.encoder.layer.2.output.LayerNorm.weight torch.Size([768])\n",
            "roberta.encoder.layer.2.output.LayerNorm.bias torch.Size([768])\n",
            "roberta.encoder.layer.3.attention.self.query.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.3.attention.self.query.bias torch.Size([768])\n",
            "roberta.encoder.layer.3.attention.self.key.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.3.attention.self.key.bias torch.Size([768])\n",
            "roberta.encoder.layer.3.attention.self.value.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.3.attention.self.value.bias torch.Size([768])\n",
            "roberta.encoder.layer.3.attention.output.dense.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.3.attention.output.dense.bias torch.Size([768])\n",
            "roberta.encoder.layer.3.attention.output.LayerNorm.weight torch.Size([768])\n",
            "roberta.encoder.layer.3.attention.output.LayerNorm.bias torch.Size([768])\n",
            "roberta.encoder.layer.3.intermediate.dense.weight torch.Size([3072, 768])\n",
            "roberta.encoder.layer.3.intermediate.dense.bias torch.Size([3072])\n",
            "roberta.encoder.layer.3.output.dense.weight torch.Size([768, 3072])\n",
            "roberta.encoder.layer.3.output.dense.bias torch.Size([768])\n",
            "roberta.encoder.layer.3.output.LayerNorm.weight torch.Size([768])\n",
            "roberta.encoder.layer.3.output.LayerNorm.bias torch.Size([768])\n",
            "roberta.encoder.layer.4.attention.self.query.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.4.attention.self.query.bias torch.Size([768])\n",
            "roberta.encoder.layer.4.attention.self.key.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.4.attention.self.key.bias torch.Size([768])\n",
            "roberta.encoder.layer.4.attention.self.value.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.4.attention.self.value.bias torch.Size([768])\n",
            "roberta.encoder.layer.4.attention.output.dense.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.4.attention.output.dense.bias torch.Size([768])\n",
            "roberta.encoder.layer.4.attention.output.LayerNorm.weight torch.Size([768])\n",
            "roberta.encoder.layer.4.attention.output.LayerNorm.bias torch.Size([768])\n",
            "roberta.encoder.layer.4.intermediate.dense.weight torch.Size([3072, 768])\n",
            "roberta.encoder.layer.4.intermediate.dense.bias torch.Size([3072])\n",
            "roberta.encoder.layer.4.output.dense.weight torch.Size([768, 3072])\n",
            "roberta.encoder.layer.4.output.dense.bias torch.Size([768])\n",
            "roberta.encoder.layer.4.output.LayerNorm.weight torch.Size([768])\n",
            "roberta.encoder.layer.4.output.LayerNorm.bias torch.Size([768])\n",
            "roberta.encoder.layer.5.attention.self.query.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.5.attention.self.query.bias torch.Size([768])\n",
            "roberta.encoder.layer.5.attention.self.key.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.5.attention.self.key.bias torch.Size([768])\n",
            "roberta.encoder.layer.5.attention.self.value.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.5.attention.self.value.bias torch.Size([768])\n",
            "roberta.encoder.layer.5.attention.output.dense.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.5.attention.output.dense.bias torch.Size([768])\n",
            "roberta.encoder.layer.5.attention.output.LayerNorm.weight torch.Size([768])\n",
            "roberta.encoder.layer.5.attention.output.LayerNorm.bias torch.Size([768])\n",
            "roberta.encoder.layer.5.intermediate.dense.weight torch.Size([3072, 768])\n",
            "roberta.encoder.layer.5.intermediate.dense.bias torch.Size([3072])\n",
            "roberta.encoder.layer.5.output.dense.weight torch.Size([768, 3072])\n",
            "roberta.encoder.layer.5.output.dense.bias torch.Size([768])\n",
            "roberta.encoder.layer.5.output.LayerNorm.weight torch.Size([768])\n",
            "roberta.encoder.layer.5.output.LayerNorm.bias torch.Size([768])\n",
            "roberta.encoder.layer.6.attention.self.query.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.6.attention.self.query.bias torch.Size([768])\n",
            "roberta.encoder.layer.6.attention.self.key.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.6.attention.self.key.bias torch.Size([768])\n",
            "roberta.encoder.layer.6.attention.self.value.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.6.attention.self.value.bias torch.Size([768])\n",
            "roberta.encoder.layer.6.attention.output.dense.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.6.attention.output.dense.bias torch.Size([768])\n",
            "roberta.encoder.layer.6.attention.output.LayerNorm.weight torch.Size([768])\n",
            "roberta.encoder.layer.6.attention.output.LayerNorm.bias torch.Size([768])\n",
            "roberta.encoder.layer.6.intermediate.dense.weight torch.Size([3072, 768])\n",
            "roberta.encoder.layer.6.intermediate.dense.bias torch.Size([3072])\n",
            "roberta.encoder.layer.6.output.dense.weight torch.Size([768, 3072])\n",
            "roberta.encoder.layer.6.output.dense.bias torch.Size([768])\n",
            "roberta.encoder.layer.6.output.LayerNorm.weight torch.Size([768])\n",
            "roberta.encoder.layer.6.output.LayerNorm.bias torch.Size([768])\n",
            "roberta.encoder.layer.7.attention.self.query.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.7.attention.self.query.bias torch.Size([768])\n",
            "roberta.encoder.layer.7.attention.self.key.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.7.attention.self.key.bias torch.Size([768])\n",
            "roberta.encoder.layer.7.attention.self.value.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.7.attention.self.value.bias torch.Size([768])\n",
            "roberta.encoder.layer.7.attention.output.dense.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.7.attention.output.dense.bias torch.Size([768])\n",
            "roberta.encoder.layer.7.attention.output.LayerNorm.weight torch.Size([768])\n",
            "roberta.encoder.layer.7.attention.output.LayerNorm.bias torch.Size([768])\n",
            "roberta.encoder.layer.7.intermediate.dense.weight torch.Size([3072, 768])\n",
            "roberta.encoder.layer.7.intermediate.dense.bias torch.Size([3072])\n",
            "roberta.encoder.layer.7.output.dense.weight torch.Size([768, 3072])\n",
            "roberta.encoder.layer.7.output.dense.bias torch.Size([768])\n",
            "roberta.encoder.layer.7.output.LayerNorm.weight torch.Size([768])\n",
            "roberta.encoder.layer.7.output.LayerNorm.bias torch.Size([768])\n",
            "roberta.encoder.layer.8.attention.self.query.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.8.attention.self.query.bias torch.Size([768])\n",
            "roberta.encoder.layer.8.attention.self.key.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.8.attention.self.key.bias torch.Size([768])\n",
            "roberta.encoder.layer.8.attention.self.value.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.8.attention.self.value.bias torch.Size([768])\n",
            "roberta.encoder.layer.8.attention.output.dense.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.8.attention.output.dense.bias torch.Size([768])\n",
            "roberta.encoder.layer.8.attention.output.LayerNorm.weight torch.Size([768])\n",
            "roberta.encoder.layer.8.attention.output.LayerNorm.bias torch.Size([768])\n",
            "roberta.encoder.layer.8.intermediate.dense.weight torch.Size([3072, 768])\n",
            "roberta.encoder.layer.8.intermediate.dense.bias torch.Size([3072])\n",
            "roberta.encoder.layer.8.output.dense.weight torch.Size([768, 3072])\n",
            "roberta.encoder.layer.8.output.dense.bias torch.Size([768])\n",
            "roberta.encoder.layer.8.output.LayerNorm.weight torch.Size([768])\n",
            "roberta.encoder.layer.8.output.LayerNorm.bias torch.Size([768])\n",
            "roberta.encoder.layer.9.attention.self.query.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.9.attention.self.query.bias torch.Size([768])\n",
            "roberta.encoder.layer.9.attention.self.key.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.9.attention.self.key.bias torch.Size([768])\n",
            "roberta.encoder.layer.9.attention.self.value.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.9.attention.self.value.bias torch.Size([768])\n",
            "roberta.encoder.layer.9.attention.output.dense.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.9.attention.output.dense.bias torch.Size([768])\n",
            "roberta.encoder.layer.9.attention.output.LayerNorm.weight torch.Size([768])\n",
            "roberta.encoder.layer.9.attention.output.LayerNorm.bias torch.Size([768])\n",
            "roberta.encoder.layer.9.intermediate.dense.weight torch.Size([3072, 768])\n",
            "roberta.encoder.layer.9.intermediate.dense.bias torch.Size([3072])\n",
            "roberta.encoder.layer.9.output.dense.weight torch.Size([768, 3072])\n",
            "roberta.encoder.layer.9.output.dense.bias torch.Size([768])\n",
            "roberta.encoder.layer.9.output.LayerNorm.weight torch.Size([768])\n",
            "roberta.encoder.layer.9.output.LayerNorm.bias torch.Size([768])\n",
            "roberta.encoder.layer.10.attention.self.query.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.10.attention.self.query.bias torch.Size([768])\n",
            "roberta.encoder.layer.10.attention.self.key.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.10.attention.self.key.bias torch.Size([768])\n",
            "roberta.encoder.layer.10.attention.self.value.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.10.attention.self.value.bias torch.Size([768])\n",
            "roberta.encoder.layer.10.attention.output.dense.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.10.attention.output.dense.bias torch.Size([768])\n",
            "roberta.encoder.layer.10.attention.output.LayerNorm.weight torch.Size([768])\n",
            "roberta.encoder.layer.10.attention.output.LayerNorm.bias torch.Size([768])\n",
            "roberta.encoder.layer.10.intermediate.dense.weight torch.Size([3072, 768])\n",
            "roberta.encoder.layer.10.intermediate.dense.bias torch.Size([3072])\n",
            "roberta.encoder.layer.10.output.dense.weight torch.Size([768, 3072])\n",
            "roberta.encoder.layer.10.output.dense.bias torch.Size([768])\n",
            "roberta.encoder.layer.10.output.LayerNorm.weight torch.Size([768])\n",
            "roberta.encoder.layer.10.output.LayerNorm.bias torch.Size([768])\n",
            "roberta.encoder.layer.11.attention.self.query.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.11.attention.self.query.bias torch.Size([768])\n",
            "roberta.encoder.layer.11.attention.self.key.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.11.attention.self.key.bias torch.Size([768])\n",
            "roberta.encoder.layer.11.attention.self.value.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.11.attention.self.value.bias torch.Size([768])\n",
            "roberta.encoder.layer.11.attention.output.dense.weight torch.Size([768, 768])\n",
            "roberta.encoder.layer.11.attention.output.dense.bias torch.Size([768])\n",
            "roberta.encoder.layer.11.attention.output.LayerNorm.weight torch.Size([768])\n",
            "roberta.encoder.layer.11.attention.output.LayerNorm.bias torch.Size([768])\n",
            "roberta.encoder.layer.11.intermediate.dense.weight torch.Size([3072, 768])\n",
            "roberta.encoder.layer.11.intermediate.dense.bias torch.Size([3072])\n",
            "roberta.encoder.layer.11.output.dense.weight torch.Size([768, 3072])\n",
            "roberta.encoder.layer.11.output.dense.bias torch.Size([768])\n",
            "roberta.encoder.layer.11.output.LayerNorm.weight torch.Size([768])\n",
            "roberta.encoder.layer.11.output.LayerNorm.bias torch.Size([768])\n",
            "classifier.dense.weight torch.Size([768, 768])\n",
            "classifier.dense.bias torch.Size([768])\n",
            "classifier.out_proj.weight torch.Size([2, 768])\n",
            "classifier.out_proj.bias torch.Size([2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(batch):\n",
        "    return tokenizer(\n",
        "        batch[\"sentence\"],     # transform each sentences in a numerical format (input_ids, attention_mask)\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=128     # sst2 contains small sentences\n",
        "    )"
      ],
      "metadata": {
        "id": "QPchduU7OH6T"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_sst2 = sst2.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "6531f0bc4cef499f844571936d1f144e",
            "d95ca7a5ad5b493f803b45d89cac95b1",
            "3428c655ffef4ae2b8875ced14291bb8",
            "47ea253f4cd54860b404f4f5a12f1b8b",
            "071fe898b92d46aba9c0842bbd1b28eb",
            "331d5668b4f243bda95a59bc9870ad6b",
            "52e5f59d9cb343ed9b870b0764c3b288",
            "ef9a5ef8687f41779e60492e7e9344fb",
            "8f2813785aa94a9fbebb490c625b92cf",
            "cfccd50ede6e4b9784792f98187ef1b0",
            "dd167b9772e84325a3c113e12b0a60fe"
          ]
        },
        "id": "FwLcjmEJQeWn",
        "outputId": "a5bfd4fa-9c17-4bfb-f03b-b6f367b8cc5a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/872 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6531f0bc4cef499f844571936d1f144e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we remove the columns idx and sentence because sentence is only useful for the tokenisation."
      ],
      "metadata": {
        "id": "vRdD3f06RJCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_sst2 = encoded_sst2.remove_columns([\"sentence\", \"idx\"])"
      ],
      "metadata": {
        "id": "TgUZ9MhPQkEf"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_sst2 = encoded_sst2.rename_column(\"label\", \"labels\")"
      ],
      "metadata": {
        "id": "WCxZtCY8RWFx"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_sst2.set_format(\"torch\")"
      ],
      "metadata": {
        "id": "s9svUqWYRY_u"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    acc = accuracy_metric.compute(predictions=predictions, references=labels)\n",
        "    return acc"
      ],
      "metadata": {
        "id": "N_AowZPlRduU"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./teacher_en_xlmr_sst2\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    logging_steps=0.15,\n",
        ")\n"
      ],
      "metadata": {
        "id": "nnE0EVHjRsKh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e1c5c52-1430-4bb7-bf84-2c8cf75cf220"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=encoded_sst2[\"train\"],\n",
        "    eval_dataset=encoded_sst2[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqvqkDsLTpiq",
        "outputId": "bdcfb2e9-6c34-4b91-ff24-a33ba03ee718"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4194284732.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "mfiRt7QYVnlA",
        "outputId": "85cc5689-6135-491b-e412-c4fc9b91a984"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4210' max='4210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4210/4210 28:14, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Model Preparation Time</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.223000</td>\n",
              "      <td>0.248062</td>\n",
              "      <td>0.011000</td>\n",
              "      <td>0.923165</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='110' max='55' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [55/55 28:52]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=4210, training_loss=0.2910549317856016, metrics={'train_runtime': 1695.4537, 'train_samples_per_second': 39.723, 'train_steps_per_second': 2.483, 'total_flos': 4430066616860160.0, 'train_loss': 0.2910549317856016, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_results = trainer.evaluate(encoded_sst2[\"validation\"])\n",
        "print(val_results)\n"
      ],
      "metadata": {
        "id": "XA129YbXuzAG",
        "outputId": "97e5781f-308e-4f29-c4c9-a66f87761255",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='55' max='55' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [55/55 00:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.2480616420507431, 'eval_model_preparation_time': 0.011, 'eval_accuracy': 0.9231651376146789, 'eval_runtime': 5.6266, 'eval_samples_per_second': 154.977, 'eval_steps_per_second': 9.775, 'epoch': 1.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Donc tu ne peux pas faire une évaluation standard dessus.\n",
        "\n",
        "Dans le benchmark GLUE :\n",
        "\n",
        "Les labels du test de SST-2 ne sont pas publics.\n",
        "\n",
        "Ils sont remplacés par des valeurs fictives (-1) pour empêcher l’entraînement après test.\n",
        "\n",
        "Ce set est prévu pour être soumis à un serveur de compétition, pas pour être utilisé localement."
      ],
      "metadata": {
        "id": "s_TYI95Ust7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_dir = \"teacher_en_sst2\"\n",
        "trainer.save_model(save_dir)\n",
        "tokenizer.save_pretrained(save_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXl2HGW-j4ck",
        "outputId": "f72e1e22-0159-482e-ef64-633d1ab31982"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('teacher_en_sst2/tokenizer_config.json',\n",
              " 'teacher_en_sst2/special_tokens_map.json',\n",
              " 'teacher_en_sst2/sentencepiece.bpe.model',\n",
              " 'teacher_en_sst2/added_tokens.json',\n",
              " 'teacher_en_sst2/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ]
}